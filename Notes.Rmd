---
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

# Notes

These are my notes for the "Walking Through Postgres" talk at the Ann Arbor Computer Society Meetup on March 6th.

```{r, include=FALSE}
knitr::opts_chunk$set(
  eval = FALSE
)
```

## Installing Postgres

The very first thing we have to do is create a new database cluster.

I'm going to use AWS RDS Postgres to host my database:

[https://console.aws.amazon.com/rds/](https://console.aws.amazon.com/rds/)

While that is starting up I'll show how to run a Postgres database locally.

### System Specfic Instructions

#### macOS

Install using EnterpriseDB, BigSQL, Postgres.app, Fink, MacPorts, or Homebrew

```{bash}
brew install postgres
brew services start postgres
```
#### Windows

EnterpriseDB, BigSQL

#### Ubuntu

Install using EnterpriseDB or PostgreSQL Apt Repository

```{bash}
sudo apt install postgresql
sudo -u postgres psql
```

#### Docker

```{bash}
docker run \
  --name postgres \
  -e POSTGRES_PASSWORD=postgres \
  -v /tmp/postgresdb:/var/lib/postgresql/data \
  postgres:latest
```

If you use Docker to run your database be sure to persist the `PGDATA` directory _outside_ of the Docker container!

### General

The PostgreSQL database cluster is a collection of databases managed by a single server instance.

`pg_ctl` is a utility for initializing a PostgreSQL database cluster, starting, stopping, or restarting the PostgreSQL database server, or displaying the status of a running server.

We can use `pg_ctl` to initialize a new database:

```{bash}
pg_ctl initdb --pgdata=/Users/${USER}/postgres_demo
```

The `--pgdata` flag lets us specify the data directory for this Postgres database.

After we've created the database we can start it:

```{bash}
pg_ctl -D /Users/${USER}/postgres_demo -l logfile start
```

Once our database has started up we can connect to it using the `psql` (default) or `pgcli` command line utilities.

```{bash}
psql postgres_demo
```

By default the PostgreSQL database cluster has several databases and we can view them by specifying the `-l` flag:

```{bash}
psql -X -l
```

Note that I use the `-X` flag to tell `psql` to ignore my startup file (.psqlrc).

#### Creating a new database

We just created a new database cluster, which contains several databases. However in the future we may want to create additional databases.

Use the `createdb` command to create a new database in the PostgreSQL database cluster.

```{bash}
createdb project_db
psql -X -l
```

#### Enabling external connections

So far we've just been interacting with a database running locally, but what if we wanted to configure a database running on a remote server?

There are two important files that need to be modified to allow external clients to connect to the database.

* `postgresql.conf` - Specifies the configuration for the server

* `pg_hba.conf` - Specifies the configuration file for host-based authentication

Modify `pg_hba.conf`:

```{text}
host    project_db  all 0.0.0.0/0   trust
```

Modify `postgresql.conf`:

```{bash}
listen_addresses = '*'
```

Then restart the database

```{bash}
pg_ctl -D postgres_demo restart
```

Now external clients should be able to connect to the database.

Note that you'd typically configure the server to accept connections only from within your network, VPC, load balancer, etc.

## Connecting to Databases

There are a few different ways to form connections using the CLI client, `psql`.

First, if the database is running locally you can just use the database name:

```{bash}
psql postgres_demo
```

Second, you can specify connection parameters using commandline flags:

```{bash}
psql -U user -h localhost -p 5432 -d postgres_demo
```

Third, you can set and use environment variables:

````{bash}
PGDATABASE=postgres_demo psql
```

Environment variables:

* `PGDATABASE`
* `PGHOST`
* `PGPORT`
* `PGUSER`
* `PGPASSWORD` (probably don't specify this one)

Fourth, you can use a connection string:

```{bash}
psql postgres://user:pwd@host:port/dbname
```

Lastly, you can use any combination of these with a .pgpass file.

Add entries to .pgpass file like this:

```{text}
hostname:port:database:username:password
localhost:5432:*:ellis:hunter1
```

You can use `*` to wildcard all or part of a field, for example to use the same username and password to connect to different databases on the same server.

***

Switching back to AWS RDS instance.

# Example: DNS Queries

Now that we know how to connect to our RDS instance, the next step is to setup tables for our data.

We're going to create the following tables:

* `blocks` - IP address blocks
* `locations` - world cities data
* `domains` - domain names resolved to IP address
* `queries` - DNS queries on the client's network

For each DNS query we'll lookup the resolved IP address and then use the IP address to lookup the location.

## Creating tables

Tables are created using the `CREATE TABLE` command.

```{sql}
CREATE TABLE blocks (
  network                        CIDR,
  geoname_id                     INTEGER,
  registered_country_geoname_id  INTEGER,
  represented_country_geoname_id INTEGER,
  is_anonymous_proxy             BOOLEAN,
  is_satellite_provider          BOOLEAN,
  postal_code                    TEXT,
  latitude                       NUMERIC,
  longitude                      NUMERIC,
  accuracy_radius                INTEGER
);

CREATE TABLE locations (
  geoname_id             INTEGER,
  locale_code            VARCHAR(2),
  continent_code         VARCHAR(2),
  continent_name         VARCHAR(13),
  country_iso_code       VARCHAR(2),
  country_name           VARCHAR(44),
  subdivision_1_iso_code VARCHAR(3),
  subdivision_1_name     VARCHAR(52),
  subdivision_2_iso_code VARCHAR(3),
  subdivision_2_name     VARCHAR(38),
  city_name              VARCHAR(63),
  metro_code             INTEGER,
  time_zone              VARCHAR(30),
  is_in_european_union   BOOLEAN
);

CREATE TABLE domains (
  domain  TEXT,
  address INET,
  created TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE queries (
  id        INTEGER,
  timestamp TIMESTAMP,
  type      INTEGER,
  status    INTEGER,
  domain    TEXT,
  client    INET,
  forward   INET
);
```

## Loading data

Data can inserted in bulk using the `\copy` command. This is much more efficient than `INSERT` when loading large amounts of data.

In this case the files the data are CSV files in a local directory. We can specifiy the delimiter and that the files have a header.

```{sql}
\copy blocks FROM 'GeoLite2-City-Blocks-IPv4.csv' DELIMITER ',' CSV HEADER;
\copy blocks FROM 'GeoLite2-City-Blocks-IPv6.csv' DELIMITER ',' CSV HEADER;
\copy locations FROM 'GeoLite2-City-Locations-en.csv' DELIMITER ',' CSV HEADER;
```

## Indexing

After we've added our data, we can add indexes to the tables. We load the data before adding indexes because indexes slow write operations and we wanted to load the data as quickly as possible. In the future we'll be performing fewer write operations at once.

The most basic way to create an index is as follows:

```{sql}
CREATE INDEX blocks_geoname_idx ON blocks (geoname_id);
```

This creates a simple B-tree index on the `geoname_id` column in the `blocks` table.

Sometimes we vant to use a different index type. Postgres provides several index types: B-tree, Hash, GiST, SP-GiST, GIN and BRIN.

| Type | Use case |
|------|----------|
| B-tree | Default type, comparison operators (<, <=, =, >=, >) |
| Hash | Simple equality comparisons, i.e. =, not recommended |
| GiST | Special types, e.g. two-dimensional geometric data, text data |
| SP-GiST | Similar to GiST, non-balanced disk-based data structures e.g. quadtrees, k-d trees, and radix trees |
| GIN | Inverted indexes, multiple values to one row |
| BRIN | Very large tables in which certain columns have some natural correlation with their physical location within the table |

If you don't know which type to use, start with B-tree and then try others.

Because we are working with network addresses we can use a `GIST` index (i.e. Generalized Search Tree):

```{sql}
CREATE INDEX blocks_network_idx ON blocks USING GIST (network inet_ops);
```

We can make similar indexes on other tables:

```{sql}
CREATE UNIQUE INDEX locations_geoname_idx ON locations (geoname_id);
CREATE INDEX locations_country_name_idx ON locations (country_name);

CREATE UNIQUE INDEX domains_domain_idx ON domains (domain);
CREATE INDEX domains_address_idx ON domains USING GIST (address);

CREATE UNIQUE INDEX queries_id_idx ON queries (id);
CREATE INDEX queries_domain_idx ON queries (domain);
CREATE INDEX queries_timestamp_idx ON queries (timestamp);
CREATE INDEX queries_day_timestamp_idx ON queries (DATE_TRUNC('d', timestamp));
```

These indexes drastically improve query performance.

Notice the last index we made includes an expression, `DATE_TRUC('d', timestamp)`, as the target. This is called an _expression_ index, which lets you to index and search the result of a function on the column.

Postgres has support for _partial_ indexes -- indexes that cover only a subset of the table.

```{sql}
CREATE INDEX queries_domain_partial_indx
ON queries (domain)
WHERE status IN (2, 3);
```

Postgres also supports multi-column indexes.

```{sql}
CREATE INDEX queries_domain_date_idx
ON queries (domain, DATE_TRUNC('d', timestamp));
```

Multi-column indexes will be used implicitly if you specify a `WHERE` clause that only includes the first column of a multi-column index.

## Querying the data

Queries are easy (until they're not).

```{sql}
SELECT * FROM queries LIMIT 10;
```

### Joins

| Type | Description |
|------|-------------|
| JOIN | Join |
| LEFT JOIN | Join |
| RIGHT JOIN | Join |
| FULL JOIN | Join |
| JOIN | Join |

Join tables:

```{sql}
SELECT *
FROM blocks
JOIN locations ON (blocks.geoname_id=locations.geoname_id);
```

If you want to join tables by the same column name, you can use the `USING` syntax instead of lengthier `ON` syntax:

```{sql}
SELECT *
FROM blocks
JOIN locations USING (geoname_id);
```



```{sql}
SELECT
  domain,
  n,
  address,
  network,
  (latitude, longitude) AS coordiantes,
  locations.country_iso_code,
  city_name AS city,
  subdivision_1_name AS state,
  country_name AS country,
  continent_name AS continent
FROM (
       SELECT
         domain,
         COUNT(id) AS n
       FROM queries
       WHERE
         status IN (2, 3)
       GROUP BY domain
       ORDER BY n DESC
     ) domain_counts
     JOIN domains USING (domain)
     JOIN blocks ON (domains.address << blocks.network)
     JOIN locations USING (geoname_id)
ORDER BY n DESC;
```


***

# Basic Administration

### Creating Roles

Roles are "users" and "groups".

```{sql}
CREATE ROLE dbadmin NOLOGIN NOINHERIT SUPERUSER;
CREATE ROLE bob;
GRANT dbadmin TO bob;
```

```{sql}
CREATE ROLE datascientist;
ALTER DEFAULT PERMISSIONS IN SCHEMA public GRANT SELECT ON TABLES TO datascientist;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO datascientist;
CREATE ROLE julia LOGIN PASSWORD 'hunter1';
GRANT datascientist TO julia;
```
